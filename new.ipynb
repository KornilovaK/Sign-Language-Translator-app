{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7277532"
      },
      "source": [
        "## Imports"
      ],
      "id": "d7277532"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgCrd11DR2Xn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24885760-dfbd-4b04-f487-9c0f9aae1d99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.9.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.0/33.0 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (23.3.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.9/dist-packages (from mediapipe) (4.6.0.66)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (22.2.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from mediapipe) (3.5.3)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (3.19.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from mediapipe) (1.22.4)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (4.39.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (23.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (8.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.15.0)\n",
            "Installing collected packages: mediapipe\n",
            "Successfully installed mediapipe-0.9.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe"
      ],
      "id": "XgCrd11DR2Xn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eea23a4"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import mediapipe as mp\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot"
      ],
      "id": "3eea23a4"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPGQ06dCoUV3",
        "outputId": "3d86711b-dba2-4df0-9d67-46328be89089"
      },
      "id": "XPGQ06dCoUV3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e6a5114"
      },
      "source": [
        "## Mediapipe functions"
      ],
      "id": "3e6a5114"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StrxwpXARwj9"
      },
      "source": [
        "####2"
      ],
      "id": "StrxwpXARwj9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ae7d944"
      },
      "outputs": [],
      "source": [
        "def marks(results):\n",
        "    marks = [0 for i in range(126)]\n",
        "    num_hands = len(results.multi_handedness)\n",
        "    for i in range(num_hands):\n",
        "        isLeft = results.multi_handedness[i].classification[0].label == \"Left\"\n",
        "        \n",
        "        landmarks = results.multi_hand_world_landmarks[i]\n",
        "        if isLeft:\n",
        "            c = 0\n",
        "            #count = 0\n",
        "            for l in landmarks.landmark:\n",
        "              #if count % 2 == 0:\n",
        "                marks[c] = l.x\n",
        "                marks[c+1] = l.y\n",
        "                marks[c+2] = l.z\n",
        "                c += 3\n",
        "              #count += 1\n",
        "        else:\n",
        "            c = 63\n",
        "            #count = 0\n",
        "            for l in landmarks.landmark:\n",
        "              #if count % 2 == 0:\n",
        "                marks[c] = l.x\n",
        "                marks[c+1] = l.y\n",
        "                marks[c+2] = l.z\n",
        "                c += 3\n",
        "              #count += 1\n",
        "    return np.array(marks)"
      ],
      "id": "2ae7d944"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3b72657"
      },
      "outputs": [],
      "source": [
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "mp_hands = mp.solutions.hands\n",
        "\n",
        "def mediapipe_detection2(image):\n",
        "    image.flags.writeable = False\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    results = hands.process(image)\n",
        "    image.flags.writeable = True\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "    return image, results\n",
        "\n",
        "def draw(image, results):\n",
        "    if results.multi_hand_landmarks:\n",
        "        for hand_landmarks in results.multi_hand_landmarks:\n",
        "          mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
        "                                    mp_drawing_styles.get_default_hand_landmarks_style(),\n",
        "                                    mp_drawing_styles.get_default_hand_connections_style())            "
      ],
      "id": "a3b72657"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### test"
      ],
      "metadata": {
        "id": "Qosa8NenX_4T"
      },
      "id": "Qosa8NenX_4T"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "29503102"
      },
      "outputs": [],
      "source": [
        "sequence = []\n",
        "cap = cv2.VideoCapture(\"/content/drive/MyDrive/data/words/Познакомиться/video5215591976824481994.mp4\")\n",
        "with mp_hands.Hands(model_complexity=0, min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
        "    while cap.isOpened():\n",
        "        success, image = cap.read()\n",
        "        if not success:\n",
        "            continue\n",
        "        #image = cv2.flip(image, 1)\n",
        "        image, results = mediapipe_detection2(image)  \n",
        "        draw(image, results)\n",
        "        \n",
        "        if cv2.waitKey(5) & 0xFF == 27:\n",
        "            break\n",
        "            \n",
        "        if results.multi_hand_world_landmarks:\n",
        "            keypoints = marks(results)\n",
        "            \n",
        "        else:\n",
        "          keypoints = np.zeros(126)\n",
        "        sequence.append(keypoints)\n",
        "        if len(sequence) == 20:\n",
        "            out = model.predict(np.array(sequence).reshape(1, 20, 126))\n",
        "            print(out[0])\n",
        "            sequence = []\n",
        "\n",
        "cap.release()"
      ],
      "id": "29503102"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "901fdab6"
      },
      "outputs": [],
      "source": [
        "cv2.destroyAllWindows()"
      ],
      "id": "901fdab6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdb2c5cf"
      },
      "source": [
        "## Make dirs for npy data"
      ],
      "id": "bdb2c5cf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa201629"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/drive/MyDrive/data/words'"
      ],
      "id": "aa201629"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9466213"
      },
      "outputs": [],
      "source": [
        "DATA_PATH = '/content/drive/MyDrive/code/data126_npy2/слова85'\n",
        "no_sequences = 85"
      ],
      "id": "d9466213"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f4ec144"
      },
      "outputs": [],
      "source": [
        "#actions = np.array(os.listdir(data_path))\n",
        "actions = np.array(['Привет', 'дела', 'До свидания', 'зовут', 'Как', 'любить', 'Я', 'Здравствуйте', 'Можно', 'Вы', 'Познакомиться', 'где',\n",
        "       'школа', 'учиться'])"
      ],
      "id": "1f4ec144"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvOsazBHXSsx",
        "outputId": "0246db12-2da1-4931-d393-e4f50005500a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Привет', 'дела', 'До свидания', 'зовут', 'Как', 'любить', 'Я',\n",
              "       'Здравствуйте', 'Можно', 'Вы', 'Познакомиться', 'где', 'школа',\n",
              "       'учиться'], dtype='<U13')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "actions"
      ],
      "id": "SvOsazBHXSsx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a267b40d"
      },
      "outputs": [],
      "source": [
        "for action in actions: \n",
        "    for sequence in range(no_sequences):\n",
        "        try: \n",
        "            os.makedirs(os.path.join(DATA_PATH, action, str(sequence)))\n",
        "        except:\n",
        "            pass"
      ],
      "id": "a267b40d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12b82a58"
      },
      "source": [
        "## Record"
      ],
      "id": "12b82a58"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f384b683"
      },
      "outputs": [],
      "source": [
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "with mp_hands.Hands(model_complexity=0, min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
        "    for action in actions:\n",
        "        for sequence in range(85):\n",
        "            path = os.path.join(data_path, action)\n",
        "            video = os.path.join(path, os.listdir(path)[sequence])\n",
        "            print(video, sequence)\n",
        "            cap = cv2.VideoCapture(video)\n",
        "            for frame_num in range(30):\n",
        "                success, image = cap.read()\n",
        "                if not success:\n",
        "                    continue\n",
        "                #image = cv2.resize(image, (1280, 720))\n",
        "                #image = cv2.flip(image, 1)\n",
        "                image, results = mediapipe_detection2(image)  \n",
        "                #draw(image, results)\n",
        "\n",
        "                '''if frame_num == 0: \n",
        "                    cv2.putText(image, 'Начинается запись', (120,200), \n",
        "                               cv2.FONT_HERSHEY_COMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
        "                    cv2.putText(image, 'Запись фреймов для {} видео {}'.format(action, sequence), (15,12), \n",
        "                               cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
        "                    cv2.imshow('MediaPipe Hands', cv2.flip(image, 1))\n",
        "                    cv2.waitKey(2000)\n",
        "                else: \n",
        "                    cv2.putText(image, 'Запись фреймов для {} видео {}'.format(action, sequence), (15,12), \n",
        "                               cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
        "                    cv2.imshow('MediaPipe Hands', cv2.flip(image, 1))'''\n",
        "                    \n",
        "                if results.multi_hand_landmarks:\n",
        "                    keypoints = marks(results)\n",
        "                else:\n",
        "                  keypoints = np.zeros(126)\n",
        "                npy_path = os.path.join(DATA_PATH, action, str(sequence), str(frame_num))\n",
        "                np.save(npy_path, keypoints)\n",
        "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "                    break\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "id": "f384b683"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "278e1dc7"
      },
      "source": [
        "## Label map"
      ],
      "id": "278e1dc7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c8e14f6"
      },
      "outputs": [],
      "source": [
        "label_map = {label:num for num, label in enumerate(actions)}"
      ],
      "id": "3c8e14f6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dd9bc51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3321a4e0-17d2-4261-f6f6-682efa4577ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Привет': 0,\n",
              " 'дела': 1,\n",
              " 'До свидания': 2,\n",
              " 'зовут': 3,\n",
              " 'Как': 4,\n",
              " 'любить': 5,\n",
              " 'Я': 6,\n",
              " 'Здравствуйте': 7,\n",
              " 'Можно': 8,\n",
              " 'Вы': 9,\n",
              " 'Познакомиться': 10,\n",
              " 'где': 11,\n",
              " 'школа': 12,\n",
              " 'учиться': 13}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "label_map"
      ],
      "id": "1dd9bc51"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "163cd81c"
      },
      "source": [
        "## Dataset"
      ],
      "id": "163cd81c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5edd2397"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "id": "5edd2397"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQ2Di2FTPkRx"
      },
      "outputs": [],
      "source": [
        "sequences, labels = [], []"
      ],
      "id": "fQ2Di2FTPkRx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1c32261",
        "outputId": "53cac096-dd8e-48d3-a7da-d08500573b0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Привет\n",
            "дела\n",
            "До свидания\n",
            "зовут\n",
            "Как\n",
            "любить\n",
            "Я\n",
            "Здравствуйте\n",
            "Можно\n",
            "Вы\n",
            "Познакомиться\n",
            "где\n",
            "школа\n",
            "учиться\n"
          ]
        }
      ],
      "source": [
        "for action in actions:\n",
        "    print(action)\n",
        "    for sequence in range(no_sequences):\n",
        "        window = []\n",
        "        for frame_num in range(10, 30):\n",
        "            res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(str(frame_num))))\n",
        "            window.append(res)\n",
        "        sequences.append(window)\n",
        "        labels.append(label_map[action])"
      ],
      "id": "f1c32261"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60f959ae"
      },
      "outputs": [],
      "source": [
        "X = np.array(sequences)"
      ],
      "id": "60f959ae"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de343232",
        "outputId": "9e689c5d-ff62-4974-ab19-57d3c2610906"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1190, 20, 126)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "X.shape"
      ],
      "id": "de343232"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2e1d2eb0"
      },
      "outputs": [],
      "source": [
        "y = to_categorical(labels).astype(int)"
      ],
      "id": "2e1d2eb0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25ced60e",
        "outputId": "4fc0135a-9c1c-477f-cae9-6f75abf9d290"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1190, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "y.shape"
      ],
      "id": "25ced60e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "990e928c"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)"
      ],
      "id": "990e928c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f259269"
      },
      "source": [
        "## Train"
      ],
      "id": "1f259269"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ea93b658"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras import *\n",
        "from tensorflow.keras.layers import *"
      ],
      "id": "ea93b658"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2134ccd4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import TensorBoard"
      ],
      "id": "2134ccd4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### lstm"
      ],
      "metadata": {
        "id": "J_0BEOmpW90M"
      },
      "id": "J_0BEOmpW90M"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uif1qP14fSz1"
      },
      "outputs": [],
      "source": [
        "X, Y = np.array(sequences), to_categorical(labels).astype(int)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.10, random_state=34, stratify=Y)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(32, return_sequences=True, activation='relu', input_shape=(20,126)))\n",
        "model.add(LSTM(64, return_sequences=True, activation='relu'))\n",
        "model.add(LSTM(32, return_sequences=False, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(actions.shape[0], activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "model.fit(X_train, Y_train, epochs=300)"
      ],
      "id": "uif1qP14fSz1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. conv 1d"
      ],
      "metadata": {
        "id": "fP_sxqHBXEOy"
      },
      "id": "fP_sxqHBXEOy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jk6NP0apXeiD"
      },
      "outputs": [],
      "source": [
        "window_size = 20\n",
        "numFilters1 = 100\n",
        "kernalSize1 = 3\n",
        "kernalSize2 = 2\n",
        "numNueronsFCL2 = 160\n",
        "dropout = 0.5\n",
        "num_classes = 14\n",
        "num_data_parameters = 126"
      ],
      "id": "Jk6NP0apXeiD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTS4TKuKXcMD"
      },
      "outputs": [],
      "source": [
        "model_m = Sequential()\n",
        "model_m.add(Reshape((window_size, num_data_parameters), input_shape=(window_size, num_data_parameters)))\n",
        "model_m.add(Conv1D(numFilters1, kernalSize1, activation='relu', input_shape=(window_size, num_data_parameters)))\n",
        "model_m.add(MaxPooling1D(2))\n",
        "model_m.add(Conv1D(numNueronsFCL2, kernalSize2, activation='relu'))\n",
        "model_m.add(GlobalAveragePooling1D())\n",
        "model_m.add(Dropout(dropout))\n",
        "model_m.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model_m.summary()"
      ],
      "id": "fTS4TKuKXcMD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rc1JJI2tXw6E"
      },
      "outputs": [],
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='/content/logs', histogram_freq=1)\n",
        "\n",
        "model_m.compile(loss='categorical_crossentropy',\n",
        "                optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 500\n",
        "\n",
        "history = model_m.fit(X_train,\n",
        "                      y_train,\n",
        "                      batch_size=BATCH_SIZE,\n",
        "                      epochs=EPOCHS,\n",
        "                      callbacks=[tensorboard_callback],\n",
        "                      validation_split=0.2,\n",
        "                      verbose=1)"
      ],
      "id": "rc1JJI2tXw6E"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. conv 1d"
      ],
      "metadata": {
        "id": "SROOQJbEXJ1S"
      },
      "id": "SROOQJbEXJ1S"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zETwLVyO48Ko"
      },
      "outputs": [],
      "source": [
        "n_timesteps, n_features, n_outputs = X.shape[1], X.shape[2], y.shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(n_outputs, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='/content/logs', histogram_freq=1)\n",
        "\n",
        "model.summary()"
      ],
      "id": "zETwLVyO48Ko"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJi_agxp6eD5"
      },
      "outputs": [],
      "source": [
        "verbose, epochs, batch_size = 1, 500, 32\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose, validation_split=0.2, callbacks=[tensorboard_callback])"
      ],
      "id": "GJi_agxp6eD5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvvY_Mmf2o_3",
        "outputId": "a8932d36-e704-485f-b32e-92b50b29fbb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0427 - accuracy: 0.9958\n",
            "0.9957982897758484\n"
          ]
        }
      ],
      "source": [
        "_, accuracy = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
        "print(accuracy)"
      ],
      "id": "PvvY_Mmf2o_3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e691839a"
      },
      "source": [
        "## Save model"
      ],
      "id": "e691839a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93916d9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76244bfc-1a7b-46c3-f698-9aff5573c705"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "model.save(\"model\")"
      ],
      "id": "93916d9b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8ed92c8"
      },
      "source": [
        "## Load model"
      ],
      "id": "d8ed92c8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4118834"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model('model2.h5')"
      ],
      "id": "c4118834"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TFlite convert"
      ],
      "metadata": {
        "id": "dTFHwWLdXV9R"
      },
      "id": "dTFHwWLdXV9R"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMN8HjyT7FDj",
        "outputId": "0e68656d-f4bf-4120-ab73-368cb46de399"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96528"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model('/content/model')\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_ops = [\n",
        "  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
        "  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
        "]\n",
        "tflite_model = converter.convert()\n",
        "open(\"model.tflite\", \"wb\").write(tflite_model)"
      ],
      "id": "RMN8HjyT7FDj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de2f02da"
      },
      "source": [
        "## Evaluate"
      ],
      "id": "de2f02da"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ca7d126d"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score, mean_squared_error, recall_score, precision_score"
      ],
      "id": "ca7d126d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfe4bb56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5dd9d09-41e2-4006-ee08-f2263c845453"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "yhat = model.predict(X_test)"
      ],
      "id": "dfe4bb56"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b62b886a"
      },
      "outputs": [],
      "source": [
        "ytrue = np.argmax(y_test, axis=1).tolist()\n",
        "yhat = np.argmax(yhat, axis=1).tolist()"
      ],
      "id": "b62b886a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f86f89c1"
      },
      "outputs": [],
      "source": [
        "multilabel_confusion_matrix(ytrue, yhat)"
      ],
      "id": "f86f89c1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8593266",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3db27c24-b8d3-4901-828e-36c810e4b641"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9327731092436975"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "accuracy_score(ytrue, yhat)"
      ],
      "id": "c8593266"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2a0009b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eca41355-f151-42a4-a3e6-52bda2f41f6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9327731092436975"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "recall_score(ytrue, yhat, average=\"micro\")"
      ],
      "id": "2a0009b1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ea2e31ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0965ea13-bd11-4128-f805-3a642f590b99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9327731092436975"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "precision_score(ytrue, yhat, average=\"micro\")"
      ],
      "id": "ea2e31ae"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26fb3b0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f50c9c2-7557-497a-f975-fa891f23ce57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7394957983193278"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "mean_squared_error(ytrue, yhat)"
      ],
      "id": "26fb3b0b"
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "d7277532",
        "3e6a5114",
        "bAQ-b9SqRuiV",
        "StrxwpXARwj9",
        "Qosa8NenX_4T",
        "bdb2c5cf",
        "12b82a58",
        "163cd81c",
        "J_0BEOmpW90M",
        "d8ed92c8",
        "de2f02da"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}